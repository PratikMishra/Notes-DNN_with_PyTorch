{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Chapter 3 - Dataset</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In sub-chapters 1-3, you will construct a basic dataset by using PyTorch and learn how to apply basic transformations to it.</p> \n",
    "<ol>\n",
    "    <li><a href=\"#Simple_Dataset\">Simple dataset</a></li>\n",
    "    <li><a href=\"#Transforms\">Transforms</a></li>\n",
    "    <li><a href=\"#Compose\">Compose</a></li>\n",
    "</ol>\n",
    "<p>In sub-chapters 4-5, you will build a dataset objects for images; many of the processes can be applied to a larger dataset. Then you will apply pre-build transforms from Torchvision Transforms to that dataset. In sub-chapters 6, you will see how to use prebuilt torchvision datasets.</p>\n",
    "<ol start=\"4\">\n",
    "    <li><a href=\"#Dataset\">Dataset Class</a></li>\n",
    "    <li><a href=\"#Torchvision\">Torchvision Transforms</a></li>\n",
    "    <li><a href=\"#Torchvisionds\">Torchvision Datasets</a></li> \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x295932dc370>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Simple_Dataset\">Simple dataset</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to create our own dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class for dataset\n",
    "\n",
    "class toy_set(Dataset):\n",
    "    \n",
    "    # Constructor with defult values \n",
    "    def __init__(self, length = 10, transform = None):\n",
    "        self.len = length\n",
    "        self.x = 2 * torch.ones(length, 2)\n",
    "        self.y = torch.ones(length, 1)\n",
    "        self.transform = transform\n",
    "     \n",
    "    # Getter\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)     \n",
    "        return sample\n",
    "    \n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us create our <code>toy_set</code> object, and find out the value on index 1 and the length of the inital dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our toy_set object:  <__main__.toy_set object at 0x00000295948943C8>\n",
      "Value on index 0 of our toy_set object:  (tensor([2., 2.]), tensor([1.]))\n",
      "Our toy_set length:  10\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset Object. Find out the value on index 1. Find out the length of Dataset Object.\n",
    "our_dataset = toy_set()\n",
    "print(\"Our toy_set object: \", our_dataset)\n",
    "print(\"Value on index 0 of our toy_set object: \", our_dataset[0])\n",
    "print(\"Our toy_set length: \", len(our_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, we can apply the same indexing convention as a <code>list</code>,\n",
    "and apply the fuction <code>len</code> on the <code>toy_set</code> object. \n",
    "\n",
    "The <code>our_dataset[0]</code> calls <code>&#95;&#95;getitem&#95;&#95;</code> function with index 0 and <code>len()</code> calls <code>&#95;&#95;len&#95;&#95;</code> function. Hence, we are able to customize the indexing and length method by <code>def &#95;&#95;getitem&#95;&#95;(self, index)</code> and <code>def &#95;&#95;len&#95;&#95;(self)</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us print out the first 3 elements and assign them to x and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  0 ; x: tensor([2., 2.]) ; y: tensor([1.])\n",
      "index:  1 ; x: tensor([2., 2.]) ; y: tensor([1.])\n",
      "index:  2 ; x: tensor([2., 2.]) ; y: tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "# Use loop to print out first 3 elements in dataset\n",
    "\n",
    "for i in range(3):\n",
    "    x, y=our_dataset[i]\n",
    "    print(\"index: \", i, '; x:', x, '; y:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset object is an Iterable; as a result, we  apply the loop directly on the dataset object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: tensor([2., 2.]) y: tensor([1.])\n",
      " x: tensor([2., 2.]) y: tensor([1.])\n",
      " x: tensor([2., 2.]) y: tensor([1.])\n",
      " x: tensor([2., 2.]) y: tensor([1.])\n",
      " x: tensor([2., 2.]) y: tensor([1.])\n",
      " x: tensor([2., 2.]) y: tensor([1.])\n",
      " x: tensor([2., 2.]) y: tensor([1.])\n",
      " x: tensor([2., 2.]) y: tensor([1.])\n",
      " x: tensor([2., 2.]) y: tensor([1.])\n",
      " x: tensor([2., 2.]) y: tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "for x,y in our_dataset:\n",
    "    print(' x:', x, 'y:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Transforms\">Transforms</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create a class for transforming the data. In this case, we will try to add 1 to x and multiply y by 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tranform class add_mult\n",
    "\n",
    "class add_mult(object):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, addx = 1, muly = 2):\n",
    "        self.addx = addx\n",
    "        self.muly = muly\n",
    "    \n",
    "    # Executor\n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x + self.addx\n",
    "        y = y * self.muly\n",
    "        sample = x, y\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a transform object:."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an add_mult transform object, and an toy_set object\n",
    "a_m = add_mult()\n",
    "data_set = toy_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the outputs of the original dataset to <code>x</code> and <code>y</code>. Then, apply the transform <code>add_mult</code> to the dataset and output the values as <code>x_</code> and <code>y_</code>, respectively.\n",
    "\n",
    "<b>Note: <code>a_m()</code> calls the <code>&#95;&#95;call&#95;&#95;</code> function directly. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0 Original x:  tensor([2., 2.]) Original y:  tensor([1.])\n",
      "Index:  0 Transformed x_: tensor([3., 3.]) Transformed y_: tensor([2.])\n",
      "Index:  1 Original x:  tensor([2., 2.]) Original y:  tensor([1.])\n",
      "Index:  1 Transformed x_: tensor([3., 3.]) Transformed y_: tensor([2.])\n",
      "Index:  2 Original x:  tensor([2., 2.]) Original y:  tensor([1.])\n",
      "Index:  2 Transformed x_: tensor([3., 3.]) Transformed y_: tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "# Use loop to print out first 3 elements in dataset\n",
    "for i in range(3):\n",
    "    x, y = data_set[i]\n",
    "    print('Index: ', i, 'Original x: ', x, 'Original y: ', y)\n",
    "    x_, y_ = a_m(data_set[i])\n",
    "    print('Index: ', i, 'Transformed x_:', x_, 'Transformed y_:', y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result, <code>x</code> has been added by 1 and y has been multiplied by 2, as <i>[2, 2] + 1 = [3, 3]</i> and <i>[1] x 2 = [2]</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply the transform object every time we create a new <code>toy_set object</code>? Remember, we have the constructor in toy_set class with the parameter <code>transform = None</code>.\n",
    "When we create a new object using the constructor, we can assign the transform object to the parameter transform, as the following code demonstrates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data_set object with add_mult object as transform\n",
    "\n",
    "cust_data_set = toy_set(transform = a_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This applied <code>a_m</code> object (a transform method) to every element in <code>cust_data_set</code> as initialized. Let us print out the first 10 elements in <code>cust_data_set</code> in order to see whether the <code>a_m</code> applied on <code>cust_data_set</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0 Original x:  tensor([2., 2.]) Original y:  tensor([1.])\n",
      "Index:  0 Transformed x_: tensor([3., 3.]) Transformed y_: tensor([2.])\n",
      "Index:  1 Original x:  tensor([2., 2.]) Original y:  tensor([1.])\n",
      "Index:  1 Transformed x_: tensor([3., 3.]) Transformed y_: tensor([2.])\n",
      "Index:  2 Original x:  tensor([2., 2.]) Original y:  tensor([1.])\n",
      "Index:  2 Transformed x_: tensor([3., 3.]) Transformed y_: tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "# Use loop to print out first 3 elements in dataset\n",
    "\n",
    "for i in range(3):\n",
    "    x, y = data_set[i]\n",
    "    print('Index: ', i, 'Original x: ', x, 'Original y: ', y)\n",
    "    x_, y_ = cust_data_set[i]\n",
    "    print('Index: ', i, 'Transformed x_:', x_, 'Transformed y_:', y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is the same as the previous method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Compose\">Compose</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compose multiple transforms on the dataset object. First, import <code>transforms</code> from <code>torchvision</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the command below when you do not have torchvision installed\n",
    "# !conda install -y torchvision\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a new transform class that multiplies each of the elements by 100: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tranform class mult\n",
    "class mult(object):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, mult = 100):\n",
    "        self.mult = mult\n",
    "        \n",
    "    # Executor\n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x * self.mult\n",
    "        y = y * self.mult\n",
    "        sample = x, y\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try to combine the transforms <code>add_mult</code> and <code>mult</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The combination of transforms (Compose):  Compose(\n",
      "    <__main__.add_mult object at 0x0000029594C26BC8>\n",
      "    <__main__.mult object at 0x0000029594C26A48>\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Combine the add_mult() and mult()\n",
    "\n",
    "data_transform = transforms.Compose([add_mult(), mult()])\n",
    "print(\"The combination of transforms (Compose): \", data_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new <code>Compose</code> object will perform each transform concurrently as shown in this figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%201/1.3.1_trasform.png\" width=\"500\" alt=\"Compose PyTorch\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x:  tensor([2., 2.]) Original y:  tensor([1.])\n",
      "Transformed x_: tensor([300., 300.]) Transformed y_: tensor([200.])\n"
     ]
    }
   ],
   "source": [
    "x,y=data_set[0]\n",
    "x_,y_=data_transform(data_set[0])\n",
    "print( 'Original x: ', x, 'Original y: ', y)\n",
    "\n",
    "print( 'Transformed x_:', x_, 'Transformed y_:', y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass the new <code>Compose</code> object (The combination of methods <code>add_mult()</code> and <code>mult</code>) to the constructor for creating <code>toy_set</code> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new toy_set object with compose object as transform\n",
    "\n",
    "compose_data_set = toy_set(transform = data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Blank -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preparation for sub-chapters 4-5</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def show_data(data_sample, shape = (28, 28)):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(shape), cmap='gray')\n",
    "    plt.title('y = ' + data_sample[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The index.csv file has information regarding each image.\n",
    " You can load the CSV file and convert it into a dataframe , using the Pandas function <code>read_csv()</code> . You can view the dataframe using the method head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ankle boot</td>\n",
       "      <td>img/fashion0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T-shirt</td>\n",
       "      <td>img/fashion1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T-shirt</td>\n",
       "      <td>img/fashion2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dress</td>\n",
       "      <td>img/fashion3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T-shirt</td>\n",
       "      <td>img/fashion4.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category             image\n",
       "0  Ankle boot  img/fashion0.png\n",
       "1     T-shirt  img/fashion1.png\n",
       "2     T-shirt  img/fashion2.png\n",
       "3       Dress  img/fashion3.png\n",
       "4     T-shirt  img/fashion4.png"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file from the URL and print out the first five samples\n",
    "directory=\"\"\n",
    "csv_file ='index.csv'\n",
    "csv_path=os.path.join(directory,csv_file)\n",
    "\n",
    "data_name = pd.read_csv(csv_path)\n",
    "data_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column of the dataframe corresponds to the type of clothing. The second column is the name of the image file corresponding to the clothing. You can obtain the path of the first file by using the method  <code> <i>DATAFRAME</i>.iloc[0, 1]</code>. The first argument corresponds to the sample number, and the second input corresponds to the column index. \n",
    "\n",
    "The number of samples corresponds to the number of rows in a dataframe. You can obtain the number of rows using the following lines of code. This will correspond the data attribute <code>len</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows:  60000\n"
     ]
    }
   ],
   "source": [
    "# Print out the total number of rows in traing dataset\n",
    "print('The number of rows: ', data_name.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next job is to load the image.\n",
    "\n",
    "You can then use the function <code>Image.open</code> to store the image to the variable <code>image</code> and display the image and class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine the directory path with file name\n",
    "image_name =data_name.iloc[1, 1]\n",
    "image_path=os.path.join(directory,image_name)\n",
    "\n",
    "# Plot the second training image\n",
    "image = Image.open(image_path)\n",
    "plt.imshow(image,cmap='gray', vmin=0, vmax=255)\n",
    "plt.title(data_name.iloc[1, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Dataset\">Dataset Class</h2>\n",
    "\n",
    "In this section, we will use the components in the last section to build a dataset class and then create an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your own dataset object\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, csv_file, data_dir, transform=None):\n",
    "        \n",
    "        # Image directory\n",
    "        self.data_dir=data_dir\n",
    "        \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        data_dircsv_file=os.path.join(self.data_dir,csv_file)\n",
    "        # Load the CSV file contians image info\n",
    "        self.data_name= pd.read_csv(data_dircsv_file)\n",
    "        \n",
    "        # Number of images in dataset\n",
    "        self.len=self.data_name.shape[0] \n",
    "    \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Image file path\n",
    "        img_name=os.path.join(self.data_dir,self.data_name.iloc[idx, 1])\n",
    "        # Open image file\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        # The class label for the image\n",
    "        y = self.data_name.iloc[idx, 0]\n",
    "        \n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y\n",
    "    \n",
    "    \n",
    "    \n",
    "# Create the dataset objects\n",
    "dataset = Dataset(csv_file=csv_file, data_dir=directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample of the image and the class y is stored in a tuple <code> dataset[sample]</code> . The image is the first element in the tuple <code> dataset[sample][0]</code> the label or class is the second element in the tuple <code> dataset[sample][1]</code>. For example you can plot the first image and class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image=dataset[0][0]\n",
    "y=dataset[0][1]\n",
    "\n",
    "plt.imshow(image,cmap='gray', vmin=0, vmax=255)\n",
    "plt.title(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Torchvision\"> Torchvision Transforms  </h2>\n",
    "\n",
    "We can apply some image transform functions on the dataset object. The iamge can be cropped and converted to a tensor. We can use <code>transform.Compose</code> we learned from the previous lab to combine the two transform functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the first element tensor:  torch.Size([1, 20, 20])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Combine two transforms: crop and convert to tensor. Apply the compose to MNIST dataset\n",
    "croptensor_data_transform = transforms.Compose([transforms.CenterCrop(20), transforms.ToTensor()])\n",
    "dataset = Dataset(csv_file=csv_file , data_dir=directory,transform=croptensor_data_transform )\n",
    "print(\"The shape of the first element tensor: \", dataset[0][0].shape)\n",
    "\n",
    "# Plot the first element in the dataset\n",
    "show_data(dataset[0],shape = (20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the image is now 20 x 20\n",
    "\n",
    "<h2 id=\"Torchvisionds\"> Torchvision Datasets  </h2>\n",
    "\n",
    "We can import a prebuilt dataset. In this case, use MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "\n",
    "# Show data by diagram\n",
    "def show_data(data_sample, shape = (28, 28)):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(shape), cmap='gray')\n",
    "    plt.title('y = ' + str(data_sample[1]))\n",
    "\n",
    "# # Import the prebuilt dataset into variable dataset\n",
    "# dataset = dsets.MNIST(\n",
    "#     root = './data', \n",
    "#     train = False, \n",
    "#     download = True, \n",
    "#     transform = transforms.ToTensor()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of the dataset object contains a tuple. Let us see whether the first element in the dataset is a tuple and what is in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the first element:  <class 'tuple'>\n",
      "The length of the tuple:  2\n",
      "The shape of the first element in the tuple:  torch.Size([1, 28, 28])\n",
      "The type of the first element in the tuple <class 'torch.Tensor'>\n",
      "The second element in the tuple:  7\n",
      "The type of the second element in the tuple:  <class 'int'>\n",
      "As the result, the structure of the first element in the dataset is (tensor([1, 28, 28]), tensor(7)).\n"
     ]
    }
   ],
   "source": [
    "# Examine whether the elements in dataset MNIST are tuples, and what is in the tuple?\n",
    "print(\"Type of the first element: \", type(dataset[0]))\n",
    "print(\"The length of the tuple: \", len(dataset[0]))\n",
    "print(\"The shape of the first element in the tuple: \", dataset[0][0].shape)\n",
    "print(\"The type of the first element in the tuple\", type(dataset[0][0]))\n",
    "print(\"The second element in the tuple: \", dataset[0][1])\n",
    "print(\"The type of the second element in the tuple: \", type(dataset[0][1]))\n",
    "print(\"As the result, the structure of the first element in the dataset is (tensor([1, 28, 28]), tensor(7)).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the output, the first element in the tuple is a cuboid tensor. As you can see, there is a dimension with only size 1, so basically, it is a rectangular tensor.<br>\n",
    "The second element in the tuple is a number tensor, which indicate the real number the image shows. As the second element in the tuple is <code>tensor(7)</code>, the image should show a hand-written 7.\n",
    "\n",
    "Let us plot the first element in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the first element in the dataset\n",
    "show_data(dataset[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
